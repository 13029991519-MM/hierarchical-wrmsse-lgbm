{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "Compute WRMSSE on d_1914-1941 for a blended submission against the official validation sales.<br>\n", "Usage:<br>\n", "    python evaluate_wrmsse_blended.py \\<br>\n", "        --submission future_finaldata/submission_with_val_blended.csv \\<br>\n", "        --sales data/sales_train_validation.csv<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from __future__ import annotations"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import argparse\n", "from pathlib import Path"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import pandas as pd"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from wrmsse_official import WRMSSEEvaluator"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def parse_args() -> argparse.Namespace:\n", "    parser = argparse.ArgumentParser(description=\"Calculate WRMSSE for a blended validation submission.\")\n", "    parser.add_argument(\"--submission\", type=Path, required=True, help=\"wide submission with F1..F28\")\n", "    parser.add_argument(\n", "        \"--sales\",\n", "        type=Path,\n", "        default=Path(\"data/sales_train_validation.csv\"),\n", "        help=\"Official sales file providing the validation truth.\",\n", "    )\n", "    return parser.parse_args()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def submission_to_long(submission_path: Path) -> pd.DataFrame:\n", "    df = pd.read_csv(submission_path)\n", "    if \"id\" not in df.columns:\n", "        raise ValueError(f\"{submission_path} missing id column\")\n", "    f_cols = [f\"F{i}\" for i in range(1, 29)]\n", "    for col in f_cols:\n", "        if col not in df.columns:\n", "            raise ValueError(f\"{submission_path} missing column {col}\")\n", "    df = df[df[\"id\"].str.endswith(\"_validation\")].copy()\n", "    df = df[[\"id\"] + f_cols]\n", "    long = df.melt(id_vars=[\"id\"], value_vars=f_cols, var_name=\"F\", value_name=\"sales\")\n", "    long[\"d\"] = long[\"F\"].str.extract(r\"F(\\d+)\").astype(int) + 1913\n", "    long[\"sales\"] = long[\"sales\"].astype(\"float32\")\n", "    return long.drop(columns=[\"F\"])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def truth_long(sales_path: Path) -> pd.DataFrame:\n", "    wide = pd.read_csv(sales_path)\n", "    day_cols = [f\"d_{d}\" for d in range(1914, 1942)]\n", "    required = [\"id\"] + day_cols\n", "    missing = [c for c in required if c not in wide.columns]\n", "    if missing:\n", "        raise ValueError(f\"{sales_path} missing columns: {missing}\")\n", "    long = wide[required].melt(id_vars=[\"id\"], var_name=\"d\", value_name=\"sales\")\n", "    long[\"d\"] = long[\"d\"].str.replace(\"d_\", \"\").astype(int)\n", "    return long"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def main() -> None:\n", "    args = parse_args()\n", "    evaluator = WRMSSEEvaluator()\n", "    truth = truth_long(args.sales)\n", "    preds = submission_to_long(args.submission)\n", "    score, _ = evaluator.compute_wrmsse(truth, preds)\n", "    print(f\"WRMSSE on validation window (d_1914-1941): {score:.6f}\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == \"__main__\":\n", "    main()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}