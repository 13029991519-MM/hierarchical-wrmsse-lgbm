{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "Compare WRMSSE across two validation windows using the shared evaluator.<br>\n", "Usage:<br>\n", "    python evaluate_wrmsse_windows.py \\<br>\n", "        --pred_current future_finaldata/submission_with_val.csv \\<br>\n", "        --pred_prev future_finaldata/submission_with_val_prev.csv \\<br>\n", "        --out_dir wrmsse_windows<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from __future__ import annotations"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import argparse\n", "import json\n", "from pathlib import Path\n", "from collections import Counter"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "import numpy as np\n", "import pandas as pd"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from wrmsse_official import WRMSSEEvaluator, SALES_FILE"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def parse_args() -> argparse.Namespace:\n", "    parser = argparse.ArgumentParser(description=\"Compute and compare WRMSSE for two windows.\")\n", "    parser.add_argument(\"--pred_current\", type=Path, required=True, help=\"Submission wide file covering d_1914-1941\")\n", "    parser.add_argument(\"--pred_prev\", type=Path, required=True, help=\"Submission wide file covering d_1886-1913\")\n", "    parser.add_argument(\"--out_dir\", type=Path, default=Path(\"wrmsse_windows\"), help=\"Directory for CSV outputs\")\n", "    return parser.parse_args()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def wide_to_long(df: pd.DataFrame, start_day: int) -> pd.DataFrame:\n", "    return WRMSSEEvaluator.wide_to_long(df, start_day=start_day)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def load_preds(path: Path) -> pd.DataFrame:\n", "    df = pd.read_csv(path)\n", "    if \"id\" not in df.columns:\n", "        raise ValueError(f\"{path} missing id column\")\n", "    return df"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def truth_long(start_day: int, end_day: int) -> pd.DataFrame:\n", "    wide = pd.read_csv(SALES_FILE)\n", "    day_cols = [f\"d_{d}\" for d in range(start_day, end_day + 1)]\n", "    id_cols = [\"id\"]\n", "    long = wide[id_cols + day_cols].melt(id_vars=[\"id\"], var_name=\"d\", value_name=\"sales\")\n", "    long[\"d\"] = long[\"d\"].str.replace(\"d_\", \"\").astype(int)\n", "    return long[long[\"d\"].between(start_day, end_day)]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def store_wrmsse(ev: WRMSSEEvaluator, truth: pd.DataFrame, pred: pd.DataFrame) -> pd.Series:\n", "    truth_proc = ev._normalize_long_df(truth)\n", "    pred_proc = ev._normalize_long_df(pred)\n", "    merged = (\n", "        truth_proc.rename(columns={\"sales\": \"y_true\"})\n", "        .merge(pred_proc.rename(columns={\"sales\": \"y_pred\"}), on=[\"id\", \"d\"], how=\"left\")\n", "        .fillna(0.0)\n", "    )\n", "    key_series = ev.level_keys[3]\n", "    tmp = merged.copy()\n", "    tmp[\"series\"] = tmp[\"id\"].map(key_series)\n", "    agg = tmp.groupby([\"series\", \"d\"], observed=True)[[\"y_true\", \"y_pred\"]].sum()\n", "    se = (agg[\"y_pred\"] - agg[\"y_true\"]) ** 2\n", "    numer = se.groupby(\"series\").mean()\n", "    scale = ev.scales[3].reindex(numer.index).fillna(1e-6)\n", "    rmsse = (numer / scale).clip(min=0).apply(np.sqrt)\n", "    weight = ev.weights[3].reindex(rmsse.index).fillna(0.0)\n", "    store_scores = (rmsse * weight).groupby(key_series).sum()\n", "    return store_scores"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def main() -> None:\n", "    args = parse_args()\n", "    out_dir = args.out_dir\n", "    out_dir.mkdir(exist_ok=True, parents=True)\n", "    ev = WRMSSEEvaluator()\n", "    current_df = load_preds(args.pred_current)\n", "    prev_df = load_preds(args.pred_prev)\n", "    truth_curr = truth_long(1914, 1941)\n", "    truth_prev = truth_long(1886, 1913)\n", "    curr_long = wide_to_long(current_df, start_day=1914)\n", "    prev_long = wide_to_long(prev_df, start_day=1886)\n", "    curr_score, curr_levels = ev.compute_wrmsse(truth_curr, curr_long)\n", "    prev_score, prev_levels = ev.compute_wrmsse(truth_prev, prev_long)\n", "    store_curr = store_wrmsse(ev, truth_curr, curr_long)\n", "    store_prev = store_wrmsse(ev, truth_prev, prev_long)\n", "    comp = (\n", "        pd.DataFrame(\n", "            {\"wrmsse_prev\": store_prev, \"wrmsse_current\": store_curr}\n", "        )\n", "        .dropna(how=\"all\")\n", "        .fillna(0.0)\n", "    )\n", "    comp[\"wrmsse_delta\"] = comp[\"wrmsse_current\"] - comp[\"wrmsse_prev\"]\n", "    def _decision(row: pd.Series) -> str:\n", "        delta = row[\"wrmsse_delta\"]\n", "        if row[\"wrmsse_current\"] < row[\"wrmsse_prev\"] - 0.01 and delta < -0.01:\n", "            return \"allow\"\n", "        if abs(delta) <= 0.01:\n", "            return \"neutral\"\n", "        return \"ban\"\n", "    comp[\"auto_decision\"] = comp.apply(_decision, axis=1)\n", "    comp.to_csv(out_dir / \"store_wrmsse_comparison.csv\")\n", "    summary = {\n", "        \"wrmsse_1886_1913\": prev_score,\n", "        \"wrmsse_1914_1941\": curr_score,\n", "        \"store_count\": len(comp),\n", "    }\n", "    decision_counts = Counter(comp[\"auto_decision\"])\n", "    summary[\"window_decisions\"] = dict(decision_counts)\n", "    summary[\"wrmsse_delta_mean\"] = float(comp[\"wrmsse_delta\"].mean())\n", "    scatter_path = out_dir / \"window_wrmsse_scatter.png\"\n", "    fig, ax = plt.subplots(figsize=(5, 5))\n", "    colors = {\"allow\": \"tab:green\", \"neutral\": \"tab:orange\", \"ban\": \"tab:red\"}\n", "    for decision, group in comp.groupby(\"auto_decision\"):\n", "        ax.scatter(\n", "            group[\"wrmsse_prev\"],\n", "            group[\"wrmsse_current\"],\n", "            s=8,\n", "            label=decision,\n", "            c=colors.get(decision, \"tab:grey\"),\n", "            alpha=0.7,\n", "            edgecolors=\"none\",\n", "        )\n", "    lim = [\n", "        min(comp[\"wrmsse_prev\"].min(), comp[\"wrmsse_current\"].min()),\n", "        max(comp[\"wrmsse_prev\"].max(), comp[\"wrmsse_current\"].max()),\n", "    ]\n", "    ax.plot(lim, lim, color=\"black\", linewidth=0.8, linestyle=\"--\", label=\"y=x\")\n", "    ax.set_xlim(lim)\n", "    ax.set_ylim(lim)\n", "    ax.set_xlabel(\"WRMSSE prev window (1886-1913)\")\n", "    ax.set_ylabel(\"WRMSSE current window (1914-1941)\")\n", "    ax.set_title(\"Store-level WRMSSE stability\")\n", "    ax.legend(frameon=False, fontsize=\"small\")\n", "    fig.tight_layout()\n", "    fig.savefig(scatter_path, dpi=150)\n", "    plt.close(fig)\n", "    with open(out_dir / \"window_wrmsse_summary.json\", \"w\", encoding=\"utf-8\") as f:\n", "        json.dump(summary, f, ensure_ascii=False, indent=2)\n", "    print(\"WRMSSE summary:\")\n", "    print(summary)\n", "    print(f\"Details saved to {out_dir / 'store_wrmsse_comparison.csv'} and {scatter_path}\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == \"__main__\":\n", "    main()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}