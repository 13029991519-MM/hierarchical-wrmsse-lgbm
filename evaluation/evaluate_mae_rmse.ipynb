{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "Quick MAE/RMSE comparison on the validation window (d_1914\u9225\u63f9_1941) between two submissions.<br>\n", "Inputs:<br>\n", "- submission_a: CSV with id, F1..F28 (e.g., original submission_with_val.csv)<br>\n", "- submission_b: CSV with id, F1..F28 (e.g., submission_with_val_reconciled.csv)<br>\n", "- sales: data/sales_train_evaluation.csv (provides d_1..d_1941 ground truth)<br>\n", "Behavior:<br>\n", "- Uses only `_validation` rows from submissions.<br>\n", "- Strips `_validation/_evaluation` suffix to align with sales ids.<br>\n", "- Computes overall MAE and RMSE on d_1914\u9225\u63f9_1941.<br>\n", "Usage (PowerShell):<br>\n", "python evaluate_mae_rmse.py `<br>\n", "  --submission_a future_finaldata/submission_with_val.csv `<br>\n", "  --submission_b future_finaldata/submission_with_val_reconciled.csv `<br>\n", "  --sales data/sales_train_evaluation.csv<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from __future__ import annotations"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import argparse\n", "import pandas as pd\n", "import numpy as np\n", "from pathlib import Path"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def parse_args() -> argparse.Namespace:\n", "    p = argparse.ArgumentParser(description=\"Compare MAE/RMSE on validation window for two submissions.\")\n", "    p.add_argument(\"--submission_a\", type=Path, required=True, help=\"Path to submission A CSV.\")\n", "    p.add_argument(\"--submission_b\", type=Path, required=True, help=\"Path to submission B CSV.\")\n", "    p.add_argument(\"--sales\", type=Path, default=Path(\"data/sales_train_evaluation.csv\"), help=\"Ground truth sales file.\")\n", "    return p.parse_args()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def load_validation(sub_path: Path) -> pd.DataFrame:\n", "    df = pd.read_csv(sub_path)\n", "    df = df[df[\"id\"].str.endswith(\"_validation\")].copy()\n", "    if df.empty:\n", "        raise ValueError(f\"No _validation rows in {sub_path}\")\n", "    f_cols = [f\"F{i}\" for i in range(1, 29)]\n", "    missing = [c for c in f_cols if c not in df.columns]\n", "    if missing:\n", "        raise ValueError(f\"{sub_path} missing columns: {missing}\")\n", "    df[\"base_id\"] = df[\"id\"].str.replace(\"_validation\", \"\", regex=False)\n", "    df = df[[\"base_id\"] + f_cols]\n", "    return df"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def load_ground_truth(sales_path: Path, base_ids: list[str]) -> pd.DataFrame:\n", "    day_cols = [f\"d_{1913 + i}\" for i in range(1, 29)]  # d_1914..d_1941\n", "    gt = pd.read_csv(sales_path)\n", "    gt[\"base_id\"] = (\n", "        gt[\"id\"]\n", "        .str.replace(\"_validation\", \"\", regex=False)\n", "        .str.replace(\"_evaluation\", \"\", regex=False)\n", "    )\n", "    gt = gt.set_index(\"base_id\").loc[base_ids, day_cols]\n", "    return gt"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def mae_rmse(pred: np.ndarray, gt: np.ndarray) -> tuple[float, float]:\n", "    diff = pred - gt\n", "    mae = np.mean(np.abs(diff))\n", "    rmse = np.sqrt(np.mean(diff ** 2))\n", "    return mae, rmse"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def main() -> None:\n", "    args = parse_args()\n", "    sub_a = load_validation(args.submission_a)\n", "    sub_b = load_validation(args.submission_b)\n\n", "    # Align base_ids\n", "    if not sub_a[\"base_id\"].equals(sub_b[\"base_id\"]):\n", "        raise ValueError(\"Submissions have different validation base_id order/content.\")\n", "    base_ids = sub_a[\"base_id\"].tolist()\n", "    gt = load_ground_truth(args.sales, base_ids)\n", "    f_cols = [f\"F{i}\" for i in range(1, 29)]\n", "    pred_a = sub_a[f_cols].to_numpy(dtype=np.float64)\n", "    pred_b = sub_b[f_cols].to_numpy(dtype=np.float64)\n", "    gt_mat = gt.to_numpy(dtype=np.float64)\n", "    mae_a, rmse_a = mae_rmse(pred_a, gt_mat)\n", "    mae_b, rmse_b = mae_rmse(pred_b, gt_mat)\n", "    print(f\"Validation window d_1914\u9225\u63f9_1941, series count {len(base_ids)}, cells {gt_mat.size}\")\n", "    print(f\"A ({args.submission_a}): MAE={mae_a:.4f}, RMSE={rmse_a:.4f}\")\n", "    print(f\"B ({args.submission_b}): MAE={mae_b:.4f}, RMSE={rmse_b:.4f}\")\n", "    delta_mae = mae_b - mae_a\n", "    delta_rmse = rmse_b - rmse_a\n", "    print(f\"Delta (B - A): MAE={delta_mae:+.4f}, RMSE={delta_rmse:+.4f}\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == \"__main__\":\n", "    main()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}