{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "Official-style WRMSSE evaluator for M5.<br>\n", "- Precomputes and caches:<br>\n", "    * hierarchy keys for 12 levels<br>\n", "    * scale (RMSSE denominator) using d_1\u9225\u63f9_1913<br>\n", "    * weights using last 28 days d_1886\u9225\u63f9_1913<br>\n", "- compute_wrmsse(y_true, y_pred) expects long data with columns:<br>\n", "    id (string), d (int day number), sales (float).<br>\n", "  Returns scalar WRMSSE and per-level breakdown.<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from __future__ import annotations"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import json\n", "import pickle\n", "from pathlib import Path\n", "from typing import Dict, Tuple"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import pandas as pd"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["DATA_DIR = Path(\"data\")\n", "CACHE_DIR = Path(\"future_finaldata/wrmsse_cache\")\n", "SALES_FILE = DATA_DIR / \"sales_train_validation.csv\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["TRAIN_END = 1913\n", "WEIGHT_SPAN = 28\n", "WEIGHT_START = TRAIN_END - WEIGHT_SPAN + 1  # 1886"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def _gen_level_keys(meta: pd.DataFrame) -> Dict[int, pd.Series]:\n", "    idx = meta[\"id\"]\n", "    keys = {\n", "        1: pd.Series([\"all\"] * len(meta), index=idx),\n", "        2: pd.Series(meta[\"state_id\"].values, index=idx),\n", "        3: pd.Series(meta[\"store_id\"].values, index=idx),\n", "        4: pd.Series(meta[\"cat_id\"].values, index=idx),\n", "        5: pd.Series(meta[\"dept_id\"].values, index=idx),\n", "        6: pd.Series((meta[\"state_id\"] + \"_\" + meta[\"cat_id\"]).values, index=idx),\n", "        7: pd.Series((meta[\"state_id\"] + \"_\" + meta[\"dept_id\"]).values, index=idx),\n", "        8: pd.Series((meta[\"store_id\"] + \"_\" + meta[\"cat_id\"]).values, index=idx),\n", "        9: pd.Series((meta[\"store_id\"] + \"_\" + meta[\"dept_id\"]).values, index=idx),\n", "        10: pd.Series(meta[\"item_id\"].values, index=idx),\n", "        11: pd.Series((meta[\"state_id\"] + \"_\" + meta[\"item_id\"]).values, index=idx),\n", "        12: pd.Series((meta[\"store_id\"] + \"_\" + meta[\"item_id\"]).values, index=idx),\n", "    }\n", "    return keys"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class WRMSSEEvaluator:\n", "    def __init__(self, sales_file: Path = SALES_FILE, cache_dir: Path = CACHE_DIR):\n", "        self.sales_file = sales_file\n", "        self.cache_dir = cache_dir\n", "        self.cache_dir.mkdir(parents=True, exist_ok=True)\n", "        self.meta = None\n", "        self.level_keys = None\n", "        self.scales = None\n", "        self.weights = None\n", "        self._load_or_build()\n", "    def _load_or_build(self):\n", "        meta_p = self.cache_dir / \"meta.pkl\"\n", "        keys_p = self.cache_dir / \"level_keys.pkl\"\n", "        scales_p = self.cache_dir / \"scales.pkl\"\n", "        weights_p = self.cache_dir / \"weights.pkl\"\n", "        if meta_p.exists() and keys_p.exists() and scales_p.exists() and weights_p.exists():\n", "            self.meta = pd.read_pickle(meta_p)\n", "            self.level_keys = pd.read_pickle(keys_p)\n", "            self.scales = pd.read_pickle(scales_p)\n", "            self.weights = pd.read_pickle(weights_p)\n", "            return\n", "        wide = pd.read_csv(self.sales_file)\n", "        id_cols = [\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"]\n", "        self.meta = wide[id_cols].copy()\n", "        day_cols = [f\"d_{d}\" for d in range(1, TRAIN_END + 1)]\n", "        long = wide[id_cols + day_cols].melt(id_vars=id_cols, var_name=\"d\", value_name=\"sales\")\n", "        long[\"d_num\"] = long[\"d\"].str.replace(\"d_\", \"\").astype(int)\n", "        self.level_keys = _gen_level_keys(self.meta)\n", "        self.scales = {}\n", "        for level, key_series in self.level_keys.items():\n", "            tmp = long.copy()\n", "            tmp[\"series\"] = tmp[\"id\"].map(key_series)\n", "            tmp = tmp[tmp[\"d_num\"] <= TRAIN_END]\n", "            tmp = tmp.sort_values([\"series\", \"d_num\"])\n", "            tmp[\"diff\"] = tmp.groupby(\"series\")[\"sales\"].diff()\n", "            denom = tmp.groupby(\"series\")[\"diff\"].apply(\n", "                lambda x: np.mean(np.square(x.dropna())) if x.dropna().size > 0 else 0.0\n", "            )\n", "            denom = denom.replace(0, 1e-6)\n", "            self.scales[level] = denom\n", "        w_long = long[(long[\"d_num\"] >= WEIGHT_START) & (long[\"d_num\"] <= TRAIN_END)]\n", "        total = w_long[\"sales\"].sum()\n", "        self.weights = {}\n", "        for level, key_series in self.level_keys.items():\n", "            tmp = w_long.copy()\n", "            tmp[\"series\"] = tmp[\"id\"].map(key_series)\n", "            sales_sum = tmp.groupby(\"series\")[\"sales\"].sum()\n", "            self.weights[level] = sales_sum / (total if total != 0 else 1e-6)\n", "        self.meta.to_pickle(meta_p)\n", "        pd.to_pickle(self.level_keys, keys_p)\n", "        pd.to_pickle(self.scales, scales_p)\n", "        pd.to_pickle(self.weights, weights_p)\n", "    def compute_wrmsse(self, y_true: pd.DataFrame, y_pred: pd.DataFrame) -> Tuple[float, Dict[int, float]]:\n", "        y_true_proc = self._normalize_long_df(y_true)\n", "        y_pred_proc = self._normalize_long_df(y_pred)\n", "        y_true_proc = y_true_proc[y_true_proc[\"id\"].isin(self.meta[\"id\"])]\n", "        y_pred_proc = y_pred_proc[y_pred_proc[\"id\"].isin(self.meta[\"id\"])]\n", "        y_true_proc[\"id\"] = y_true_proc[\"id\"].astype(str)\n", "        y_pred_proc[\"id\"] = y_pred_proc[\"id\"].astype(str)\n", "        df = y_true_proc[[\"id\", \"d\", \"sales\"]].rename(columns={\"sales\": \"y_true\"}).merge(\n", "            y_pred_proc[[\"id\", \"d\", \"sales\"]].rename(columns={\"sales\": \"y_pred\"}), on=[\"id\", \"d\"], how=\"left\"\n", "        )\n", "        df[\"y_pred\"] = df[\"y_pred\"].fillna(0.0)\n", "        per_level = {}\n", "        total_wrmsse = 0.0\n", "        for level, key_series in self.level_keys.items():\n", "            tmp = df.copy()\n", "            tmp[\"series\"] = tmp[\"id\"].map(key_series)\n", "            agg = tmp.groupby([\"series\", \"d\"], observed=True)[[\"y_true\", \"y_pred\"]].sum()\n", "            agg = agg.sort_index()\n", "            se = (agg[\"y_pred\"] - agg[\"y_true\"]) ** 2\n", "            numer = se.groupby(\"series\").mean()\n", "            scale = self.scales[level].reindex(numer.index).fillna(1e-6)\n", "            rmsse = np.sqrt(numer / scale)\n", "            weight = self.weights[level].reindex(rmsse.index).fillna(0.0)\n", "            wrmsse_level = (rmsse * weight).sum()\n", "            per_level[level] = wrmsse_level\n", "            total_wrmsse += wrmsse_level\n", "        return total_wrmsse, per_level\n", "    @staticmethod\n", "    def _normalize_long_df(df: pd.DataFrame) -> pd.DataFrame:\n", "        tmp = df.copy()\n", "        if \"d\" not in tmp.columns:\n", "            raise ValueError(\"WRMSSE data must have column 'd' (int day index).\")\n", "        if tmp[\"d\"].dtype == object:\n", "            tmp[\"d\"] = (\n", "                tmp[\"d\"]\n", "                .astype(str)\n", "                .str.replace(\"d_\", \"\", regex=False)\n", "                .str.replace(\"D_\", \"\", regex=False)\n", "                .astype(int)\n", "            )\n", "        return tmp\n", "    @staticmethod\n", "    def wide_to_long(preds_wide: pd.DataFrame, start_day: int = 1914) -> pd.DataFrame:\n", "        rows = []\n", "        value_cols = [c for c in preds_wide.columns if c.startswith(\"F\")]\n", "        for col in value_cols:\n", "            f_idx = int(col.lstrip(\"F\"))\n", "            d = start_day + f_idx - 1\n", "            temp = preds_wide[[\"id\", col]].copy()\n", "            temp = temp.rename(columns={col: \"sales\"})\n", "            temp[\"d\"] = d\n", "            rows.append(temp[[\"id\", \"d\", \"sales\"]])\n", "        if not rows:\n", "            return pd.DataFrame(columns=[\"id\", \"d\", \"sales\"])\n", "        return pd.concat(rows, ignore_index=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == \"__main__\":\n", "    print(\"WRMSSEEvaluator ready; use compute_wrmsse(y_true_long, y_pred_long).\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}