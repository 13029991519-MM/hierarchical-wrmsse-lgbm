{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["DATA_DIR = \"data\"\n", "SALES_PATH_EVAL = os.path.join(DATA_DIR, \"sales_train_evaluation.csv\")\n", "SALES_PATH_VAL = os.path.join(DATA_DIR, \"sales_train_validation.csv\")\n", "SALES_PATH = SALES_PATH_EVAL if os.path.exists(SALES_PATH_EVAL) else SALES_PATH_VAL"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if SALES_PATH == SALES_PATH_EVAL:\n", "    print(f\">>> using evaluation data ({SALES_PATH_EVAL})\")\n", "else:\n", "    print(f\">>> evaluation data missing; falling back to validation ({SALES_PATH_VAL})\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["SAMPLE_SUB_PATH = os.path.join(DATA_DIR, \"sample_submission.csv\")\n", "OUT_PATH = os.path.join(DATA_DIR, \"submission_naive_28shift.csv\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["H = 28\n", "VAL_START, VAL_END = 1914, 1941\n", "TEST_START, TEST_END = 1942, 1969"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def wide_to_long(df: pd.DataFrame, cols: list[str]) -> pd.DataFrame:\n", "    out = df[[\"id\"] + cols].melt(id_vars=\"id\", value_name=\"sales\", var_name=\"d\")\n", "    out[\"d\"] = out[\"d\"].str.replace(\"d_\", \"\", regex=False).astype(int)\n", "    return out"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(f\">>> reading {SALES_PATH}\")\n", "sales = pd.read_csv(SALES_PATH)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["hist_cols_val = [f\"d_{d}\" for d in range(VAL_START - H, VAL_END - H + 1)]\n", "val_cols = [f\"d_{d}\" for d in range(VAL_START, VAL_END + 1)]\n", "hist_cols_test = [f\"d_{d}\" for d in range(TEST_START - H, TEST_END - H + 1)]\n", "future_cols_test = [f\"d_{d}\" for d in range(TEST_START, TEST_END + 1)]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\">>> constructing val prediction via naive shift\")\n", "print(\"  val columns:\", len(val_cols), \"shifted columns:\", len(hist_cols_val))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["true_val_long = wide_to_long(sales, val_cols)\n", "pred_val_long = wide_to_long(sales, hist_cols_val)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\">>> building future predictions\")\n", "y_pred_test = sales[hist_cols_test].copy()\n", "y_pred_test[\"id\"] = sales[\"id\"].values\n", "y_pred_test = y_pred_test[[\"id\"] + hist_cols_test]\n", "y_pred_test.columns = [\"id\"] + future_cols_test"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["try:\n", "    from wrmsse_official import WRMSSEEvaluator\n", "    print(\">>> computing WRMSSE\")\n", "    evaluator = WRMSSEEvaluator()\n", "    wrmsse_val, _ = evaluator.compute_wrmsse(true_val_long, pred_val_long)\n", "    print(f\"  WRMSSE on d_{VAL_START}-{VAL_END}: {wrmsse_val:.6f}\")\n", "except ImportError:\n", "    print(\">>> wrmsse_official not available; skipping WRMSSE computation\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(f\">>> reading {SAMPLE_SUB_PATH}\")\n", "sub = pd.read_csv(SAMPLE_SUB_PATH)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["val_pred = pd.DataFrame({\"id\": sales[\"id\"].values})\n", "for i, d in enumerate(range(TEST_START, TEST_END + 1), start=1):\n", "    val_pred[f\"F{i}\"] = y_pred_test[f\"d_{d}\"]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["val_pred[\"id\"] = val_pred[\"id\"].str.replace(\"_validation\", \"_evaluation\", regex=False)\n", "eval_mask = sub[\"id\"].str.endswith(\"_evaluation\")\n", "sub_eval_ids = sub.loc[eval_mask, \"id\"]\n", "sub.loc[eval_mask, \"F1\":\"F28\"] = val_pred.set_index(\"id\").loc[sub_eval_ids].values"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sub.to_csv(OUT_PATH, index=False)\n", "print(f\">>> saved naive submission to {OUT_PATH}\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}