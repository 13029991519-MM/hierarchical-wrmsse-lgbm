{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e49653",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Quick ARIMA/SARIMAX baseline on aggregated state-level sales.\n",
    "\n",
    "What it does:\n",
    "- Reads processed store CSVs from newfinaldata.\n",
    "-, aggregates by state per day, splits train d_1–1913 and val d_1914–1941.\n",
    "- Fits a simple weekly seasonal SARIMAX per state and reports RMSE/SMAPE on val.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ca168b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c18b3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from pathlib import Path\n",
    "from typing import Dict, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a871735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7034ab0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"newfinaldata\")\n",
    "STATE_GROUPS: Dict[str, List[str]] = {\n",
    "    \"CA\": [\"CA_1\", \"CA_2\", \"CA_3\", \"CA_4\"],\n",
    "    \"TX\": [\"TX_1\", \"TX_2\", \"TX_3\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a6e9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_END = 1913\n",
    "VAL_END = 1941"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a8b1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(y_true: np.ndarray, y_pred: np.ndarray, eps: float = 1e-6) -> float:\n",
    "    num = np.abs(y_pred - y_true)\n",
    "    denom = (np.abs(y_true) + np.abs(y_pred)).clip(min=eps)\n",
    "    return float(np.mean(2.0 * num / denom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6baa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_state_series(state: str) -> pd.Series:\n",
    "    stores = STATE_GROUPS[state]\n",
    "    dfs = []\n",
    "    for store in stores:\n",
    "        path = DATA_DIR / f\"processed_{store}.csv\"\n",
    "        if not path.exists():\n",
    "            raise FileNotFoundError(f\"{path} not found\")\n",
    "        df = pd.read_csv(path, usecols=[\"d\", \"sales\"])\n",
    "        dfs.append(df)\n",
    "    df_all = pd.concat(dfs, ignore_index=True)\n",
    "    df_all[\"d_int\"] = df_all[\"d\"].str.replace(\"d_\", \"\", regex=False).astype(int)\n",
    "    agg = df_all.groupby(\"d_int\")[\"sales\"].sum().sort_index()\n",
    "    # attach a daily DateIndex to avoid statsmodels warnings\n",
    "    start_date = pd.Timestamp(\"2011-01-29\")  # matches M5 day1\n",
    "    agg.index = pd.date_range(start=start_date, periods=len(agg), freq=\"D\")\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5859c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_eval(state: str, orders: list[tuple], seasonal_orders: list[tuple]) -> None:\n",
    "    series = load_state_series(state)\n",
    "    start_date = series.index.min()\n",
    "    train_end_date = start_date + pd.Timedelta(days=TRAIN_END - 1)\n",
    "    val_end_date = start_date + pd.Timedelta(days=VAL_END - 1)\n",
    "    train = series[series.index <= train_end_date]\n",
    "    val = series[(series.index > train_end_date) & (series.index <= val_end_date)]\n",
    "    if val.empty:\n",
    "        raise ValueError(f\"No val split for state {state}\")\n",
    "\n",
    "    best = None\n",
    "    for order, seasonal_order in itertools.product(orders, seasonal_orders):\n",
    "        try:\n",
    "            model = SARIMAX(\n",
    "                train,\n",
    "                order=order,\n",
    "                seasonal_order=seasonal_order,\n",
    "                enforce_stationarity=False,\n",
    "                enforce_invertibility=False,\n",
    "            )\n",
    "            res = model.fit(disp=False)\n",
    "            preds = res.forecast(steps=len(val))\n",
    "            rmse = float(np.sqrt(mean_squared_error(val, preds)))\n",
    "            smape_val = smape(val.values, preds.values)\n",
    "            if (best is None) or (rmse < best[\"rmse\"]):\n",
    "                best = {\n",
    "                    \"order\": order,\n",
    "                    \"seasonal_order\": seasonal_order,\n",
    "                    \"rmse\": rmse,\n",
    "                    \"smape\": smape_val,\n",
    "                    \"aic\": res.aic,\n",
    "                }\n",
    "        except Exception as e:  # pragma: no cover\n",
    "            print(f\"[{state}] Failed order={order} seasonal={seasonal_order}: {e}\")\n",
    "            continue\n",
    "\n",
    "    print(f\"[{state}] Best RMSE {best['rmse']:.4f} | SMAPE {best['smape']:.4f} | order {best['order']} | seasonal {best['seasonal_order']} | AIC {best['aic']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6f3e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main() -> None:\n",
    "    # Simple search around weekly seasonality\n",
    "    orders = [(1, 0, 1), (2, 0, 2)]\n",
    "    seasonal_orders = [(0, 1, 1, 7), (1, 1, 1, 7)]\n",
    "    for state in STATE_GROUPS:\n",
    "        fit_eval(state, orders, seasonal_orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570e429c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
