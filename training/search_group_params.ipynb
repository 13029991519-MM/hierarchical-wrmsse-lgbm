{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "Global random search over store groups and model types.<br>\n", "Step1 in your workflow: for each (model_type, group) combination, run limited random search<br>\n", "and save the top-performing parameter sets for later store-level experiments.<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from __future__ import annotations"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import argparse\n", "import itertools\n", "import json\n", "import random\n", "from pathlib import Path\n", "from statistics import mean"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import lightgbm as lgb\n", "import numpy as np\n", "import pandas as pd"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from train_lgbm_baseline import (\n", "    BASE_PARAMS,\n", "    CORE_GENERATED_SCALED,\n", "    CORE_LAG_SCALED,\n", "    CORE_ROLL_SCALED,\n", "    CORE_PRICE_SCALED,\n", "    CYCLIC,\n", "    BIN_COLS,\n", "    CAT_COLS,\n", "    DATA_DIR,\n", "    EXTRA_LAG_SCALED,\n", "    EXTRA_ROLL_MEAN,\n", "    EXTRA_ROLL_STD,\n", "    EXTRA_ROLL_MED,\n", "    EXTRA_ROLL_MIN,\n", "    EXTRA_ROLL_MAX,\n", "    EXTRA_PRICE_MOMENTUM,\n", "    EXTRA_SEASONAL,\n", "    TARGET_COL,\n", "    TRAIN_END,\n", "    VAL_END,\n", "    read_store,\n", "    set_categorical,\n", ")\n", "from wrmsse_official import WRMSSEEvaluator"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["OUT_DIR = Path(\"weight_v2\")\n", "OUT_DIR.mkdir(exist_ok=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["CORE_FEATURES = (\n", "    CORE_LAG_SCALED\n", "    + CORE_ROLL_SCALED\n", "    + CORE_PRICE_SCALED\n", "    + CYCLIC\n", "    + BIN_COLS\n", "    + CAT_COLS\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["EXTRA_FEATURES = (\n", "    CORE_FEATURES\n", "    + EXTRA_LAG_SCALED\n", "    + EXTRA_ROLL_MEAN\n", "    + EXTRA_ROLL_STD\n", "    + EXTRA_ROLL_MED\n", "    + EXTRA_ROLL_MIN\n", "    + EXTRA_ROLL_MAX\n", "    + EXTRA_PRICE_MOMENTUM\n", "    + EXTRA_SEASONAL\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["GROUPS = {\n", "    \"group_a\": [\"CA_1\", \"CA_2\", \"CA_4\", \"TX_1\"],\n", "    \"group_b\": [\"CA_3\", \"WI_1\", \"WI_2\"],\n", "}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["MODEL_TYPES = {\n", "    \"main\": CORE_FEATURES,\n", "    \"c_model\": EXTRA_FEATURES,\n", "}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def random_params(base: dict) -> dict:\n", "    return {\n", "        **base,\n", "        \"learning_rate\": max(1e-3, base[\"learning_rate\"] * random.uniform(0.8, 1.2)),\n", "        \"num_leaves\": random.choice([160, 200, 255, 300, 383]),\n", "        \"feature_fraction\": random.uniform(0.6, 0.95),\n", "        \"bagging_fraction\": random.uniform(0.6, 0.95),\n", "        \"bagging_freq\": random.choice([3, 5, 7]),\n", "        \"lambda_l1\": random.choice([0.0, 0.1, 0.5]),\n", "        \"lambda_l2\": random.choice([0.5, 1.0, 2.0]),\n", "        \"max_depth\": random.choice([-1, 8, 10]),\n", "        \"min_data_in_leaf\": random.choice([100, 150, 200]),\n", "    }"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def prepare_store_df(store: str, cols: list[str]) -> pd.DataFrame:\n", "    df = read_store(store, DATA_DIR, usecols=cols)\n", "    df[\"d_int\"] = df[\"d\"].str.replace(\"d_\", \"\", regex=False).astype(int)\n", "    df[\"id\"] = df[\"id\"].str.replace(\"_evaluation\", \"_validation\", regex=False)\n", "    for col in CAT_COLS:\n", "        df[col] = df[col].astype(str)\n", "    return df"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def compute_wrmsse(ev: WRMSSEEvaluator, subset: pd.DataFrame, preds: np.ndarray) -> float:\n", "    y_true = subset[[\"id\", \"d\", TARGET_COL]].copy()\n", "    y_true[\"d\"] = y_true[\"d\"].astype(str).str.replace(\"d_\", \"\").astype(int)\n", "    y_true = y_true.rename(columns={TARGET_COL: \"sales\"})\n", "    y_pred = y_true.copy()\n", "    y_pred[\"sales\"] = preds.astype(\"float32\")\n", "    score, _ = ev.compute_wrmsse(y_true, y_pred)\n", "    return float(score)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def evaluate_params(stores: list[str], feature_cols: list[str], params: dict) -> float:\n", "    ev = WRMSSEEvaluator()\n", "    scores = []\n", "    cols = list(dict.fromkeys(feature_cols + [TARGET_COL, \"d\", \"d_int\", \"id\"]))\n", "    ev = WRMSSEEvaluator()\n", "    scores = []\n", "    for store in stores:\n", "        df = prepare_store_df(store, cols)\n", "        train_df = df[df[\"d_int\"] <= TRAIN_END].copy()\n", "        val_df = df[(df[\"d_int\"] > TRAIN_END) & (df[\"d_int\"] <= VAL_END)].copy()\n", "        if val_df.empty:\n", "            continue\n", "        for col in CAT_COLS:\n", "            train_df[col], val_df[col] = set_categorical(train_df[col], val_df[col])\n", "        feats = list(dict.fromkeys(feature_cols))\n", "        model = lgb.LGBMRegressor(**params)\n", "        model.fit(\n", "            train_df[feats],\n", "            train_df[TARGET_COL].astype(\"float32\"),\n", "            eval_set=[(val_df[feats], val_df[TARGET_COL].astype(\"float32\"))],\n", "        )\n", "        preds_val = model.predict(val_df[feats])\n", "        prev_mask = train_df[\"d_int\"].between(1886, TRAIN_END)\n", "        prev_df = train_df[prev_mask]\n", "        if prev_df.empty:\n", "            continue\n", "        preds_prev = model.predict(prev_df[feats])\n", "        score_prev = compute_wrmsse(ev, prev_df, preds_prev)\n", "        score_val = compute_wrmsse(ev, val_df, preds_val)\n", "        scores.append((score_prev + score_val) / 2.0)\n", "    return float(np.mean(scores)) if scores else float(\"inf\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def search_group(group: str, model_type: str, trials: int, top_k: int) -> None:\n", "    stores = GROUPS[group]\n", "    features = MODEL_TYPES[model_type]\n", "    base = BASE_PARAMS.copy()\n", "    results = []\n", "    for trial in range(trials):\n", "        params = random_params(base)\n", "        score = evaluate_params(stores, features, params)\n", "        results.append({\"params\": params, \"score\": score})\n", "        print(f\"[{group} | {model_type}] Trial {trial+1}/{trials}: score={score:.4f}\")\n", "    best = sorted(results, key=lambda x: x[\"score\"])[:top_k]\n", "    out_path = OUT_DIR / f\"group_params_{group}_{model_type}.json\"\n", "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n", "        json.dump(best, f, ensure_ascii=False, indent=2)\n", "    print(f\"Saved top {top_k} candidates for {group}/{model_type} to {out_path}\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def parse_args() -> argparse.Namespace:\n", "    parser = argparse.ArgumentParser(description=\"Global random search for group/model combos.\")\n", "    parser.add_argument(\"--trials\", type=int, default=10)\n", "    parser.add_argument(\"--top_k\", type=int, default=3)\n", "    parser.add_argument(\"--groups\", nargs=\"+\", default=list(GROUPS))\n", "    parser.add_argument(\"--model_types\", nargs=\"+\", default=list(MODEL_TYPES))\n", "    return parser.parse_args()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def main() -> None:\n", "    args = parse_args()\n", "    for group, model_type in itertools.product(args.groups, args.model_types):\n", "        if group not in GROUPS or model_type not in MODEL_TYPES:\n", "            continue\n", "        search_group(group, model_type, args.trials, args.top_k)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == \"__main__\":\n", "    main()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}