{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "Generate enriched features for M5 data and save to finaldata/.<br>\n", "New features added:<br>\n", "- lag_1, lag_14, lag_28 on sales<br>\n", "- rolling_mean_14/28, rolling_std_14/28 on sales<br>\n", "- price_ratio = sell_price / baseline_price<br>\n", "- discount_pct = discount / baseline_price<br>\n", "- promo_holiday = IsPromotion * IsHoliday<br>\n", "- snap_wday = snap_state * wday  (snap for the row's state)<br>\n", "Scaled versions (_scaled) are computed via min-max per file.<br>\n", "Source directory: newdata_evaluation<br>\n", "Output directory: finaldata<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from __future__ import annotations"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import pandas as pd\n", "from pathlib import Path"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["SRC_DIR = Path(\"newdata_evaluation\")\n", "OUT_DIR = Path(\"newfinaldata\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["OUT_DIR.mkdir(exist_ok=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["FILES = sorted(SRC_DIR.glob(\"processed_*.csv\"))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["New numeric features to scale<br>\n", "Base new numeric features to scale"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["NEW_NUM_COLS = [\n", "    \"lag_1\",\n", "    \"lag_14\",\n", "    \"lag_28\",\n", "    \"lag_56\",\n", "    \"lag_84\",\n", "    \"rolling_mean_14\",\n", "    \"rolling_mean_28\",\n", "    \"rolling_mean_56\",\n", "    \"rolling_mean_84\",\n", "    \"rolling_std_14\",\n", "    \"rolling_std_28\",\n", "    \"rolling_std_56\",\n", "    \"rolling_std_84\",\n", "    \"price_ratio\",\n", "    \"discount_pct\",\n", "    \"snap_wday\",\n", "    \"promo_holiday\",\n", "    \"promo_wday_sin\",\n", "    \"promo_wday_cos\",\n", "    \"discount_snap\",\n", "    # rolling median/min/max\n", "    \"rolling_median_7\",\n", "    \"rolling_median_14\",\n", "    \"rolling_median_28\",\n", "    \"rolling_median_30\",\n", "    \"rolling_median_56\",\n", "    \"rolling_median_84\",\n", "    \"rolling_min_7\",\n", "    \"rolling_min_14\",\n", "    \"rolling_min_28\",\n", "    \"rolling_min_30\",\n", "    \"rolling_min_56\",\n", "    \"rolling_min_84\",\n", "    \"rolling_max_7\",\n", "    \"rolling_max_14\",\n", "    \"rolling_max_28\",\n", "    \"rolling_max_30\",\n", "    \"rolling_max_56\",\n", "    \"rolling_max_84\",\n", "    # price momentum / z-score\n", "    \"sell_price_week_chg\",\n", "    \"sell_price_month_chg\",\n", "    \"sell_price_z28\",\n", "    \"discount_week_chg\",\n", "    \"discount_month_chg\",\n", "    \"discount_z28\",\n", "    # promo/holiday streaks\n", "    \"promo_streak\",\n", "    \"holiday_streak\",\n", "    # event distance\n", "    \"days_since_holiday\",\n", "    \"days_until_holiday\",\n", "]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for path in FILES:\n", "    print(f\"Processing {path.name} ...\")\n", "    df = pd.read_csv(path, low_memory=False)\n\n", "    # Ensure d integer for sorting/grouping (if needed)\n", "    df[\"d_int\"] = df[\"d\"].str.replace(\"d_\", \"\", regex=False).astype(int)\n", "    df = df.sort_values([\"id\", \"d_int\"])\n", "    g = df.groupby(\"id\", sort=False)[\"sales\"]\n", "    df[\"lag_1\"] = g.shift(1)\n", "    df[\"lag_14\"] = g.shift(14)\n", "    df[\"lag_28\"] = g.shift(28)\n", "    df[\"lag_56\"] = g.shift(56)\n", "    df[\"lag_84\"] = g.shift(84)\n", "    df[\"rolling_mean_14\"] = g.transform(lambda s: s.rolling(14, min_periods=1).mean())\n", "    df[\"rolling_std_14\"] = g.transform(lambda s: s.rolling(14, min_periods=1).std())\n", "    df[\"rolling_mean_28\"] = g.transform(lambda s: s.rolling(28, min_periods=1).mean())\n", "    df[\"rolling_std_28\"] = g.transform(lambda s: s.rolling(28, min_periods=1).std())\n", "    df[\"rolling_mean_56\"] = g.transform(lambda s: s.rolling(56, min_periods=1).mean())\n", "    df[\"rolling_std_56\"] = g.transform(lambda s: s.rolling(56, min_periods=1).std())\n", "    df[\"rolling_mean_84\"] = g.transform(lambda s: s.rolling(84, min_periods=1).mean())\n", "    df[\"rolling_std_84\"] = g.transform(lambda s: s.rolling(84, min_periods=1).std())\n", "    # rolling median/min/max for robustness\n", "    for win in [7, 14, 28, 30, 56, 84]:\n", "        df[f\"rolling_median_{win}\"] = g.transform(lambda s, w=win: s.rolling(w, min_periods=1).median())\n", "        df[f\"rolling_min_{win}\"] = g.transform(lambda s, w=win: s.rolling(w, min_periods=1).min())\n", "        df[f\"rolling_max_{win}\"] = g.transform(lambda s, w=win: s.rolling(w, min_periods=1).max())\n\n", "    # Price ratios\n", "    df[\"price_ratio\"] = np.where(df[\"baseline_price\"] > 0, df[\"sell_price\"] / df[\"baseline_price\"], np.nan)\n", "    df[\"discount_pct\"] = np.where(df[\"baseline_price\"] > 0, df[\"discount\"] / df[\"baseline_price\"], np.nan)\n\n", "    # Interactions\n", "    df[\"promo_holiday\"] = df[\"IsPromotion\"] * df[\"IsHoliday\"]\n", "    snap_state = np.select(\n", "        [\n", "            df[\"state_id\"] == \"CA\",\n", "            df[\"state_id\"] == \"TX\",\n", "            df[\"state_id\"] == \"WI\",\n", "        ],\n", "        [\n", "            df[\"snap_CA\"],\n", "            df[\"snap_TX\"],\n", "            df[\"snap_WI\"],\n", "        ],\n", "        default=0,\n", "    )\n", "    df[\"snap_wday\"] = snap_state * df[\"wday\"]\n", "    # Additional interactions\n", "    df[\"promo_wday_sin\"] = df[\"promo_intensity\"] * df.get(\"wday_sin\", 0)\n", "    df[\"promo_wday_cos\"] = df[\"promo_intensity\"] * df.get(\"wday_cos\", 0)\n", "    df[\"discount_snap\"] = df[\"discount_pct\"] * snap_state\n", "    # price momentum & z-score (28d)\n", "    for col in [\"sell_price\", \"discount\"]:\n", "        df[f\"{col}_week_chg\"] = df.groupby(\"item_id\")[col].pct_change(periods=7)\n", "        df[f\"{col}_month_chg\"] = df.groupby(\"item_id\")[col].pct_change(periods=28)\n", "        roll_mean = df.groupby(\"item_id\")[col].transform(lambda s: s.rolling(28, min_periods=2).mean())\n", "        roll_std = df.groupby(\"item_id\")[col].transform(lambda s: s.rolling(28, min_periods=2).std())\n", "        df[f\"{col}_z28\"] = (df[col] - roll_mean) / roll_std.replace(0, np.nan)\n", "    # promo/holiday streaks (consecutive days)\n", "    df[\"promo_streak\"] = df.groupby(\"id\")[\"IsPromotion\"].transform(\n", "        lambda s: s.groupby((s != s.shift()).cumsum()).cumcount() + 1\n", "    ) * df[\"IsPromotion\"]\n", "    df[\"holiday_streak\"] = df.groupby(\"id\")[\"IsHoliday\"].transform(\n", "        lambda s: s.groupby((s != s.shift()).cumsum()).cumcount() + 1\n", "    ) * df[\"IsHoliday\"]\n", "    # event distance (to prev/next holiday)\n", "    holiday_days = df.loc[df[\"IsHoliday\"] == 1, \"d_int\"].unique()\n", "    if len(holiday_days) > 0:\n", "        prev_map = pd.Series(holiday_days).sort_values()\n", "        next_map = prev_map\n", "        df[\"days_since_holiday\"] = df[\"d_int\"].apply(lambda x: x - prev_map[prev_map <= x].max() if any(prev_map <= x) else np.nan)\n", "        df[\"days_until_holiday\"] = df[\"d_int\"].apply(lambda x: next_map[next_map >= x].min() - x if any(next_map >= x) else np.nan)\n", "    else:\n", "        df[\"days_since_holiday\"] = np.nan\n", "    df[\"days_until_holiday\"] = df.get(\"days_until_holiday\", np.nan)\n\n", "    # Fill numeric NaNs to 0 to keep downstream models simple\n", "    NUM_COLS_TO_FILL = NEW_NUM_COLS + [\n", "        \"sell_price\",\n", "        \"baseline_price\",\n", "        \"discount\",\n", "        \"promo_intensity\",\n", "    ]\n", "    for col in NUM_COLS_TO_FILL:\n", "        if col in df.columns:\n", "            df[col] = df[col].fillna(0)\n\n", "    # Fill categorical NaNs to 'Unknown'\n", "    CAT_COLS = [\n", "        \"state_id\",\n", "        \"store_id\",\n", "        \"cat_id\",\n", "        \"dept_id\",\n", "        \"event_name_1\",\n", "        \"event_type_1\",\n", "        \"event_name_2\",\n", "        \"event_type_2\",\n", "        \"item_id\",\n", "        \"id\",\n", "    ]\n", "    for col in CAT_COLS:\n", "        if col in df.columns:\n", "            df[col] = df[col].fillna(\"Unknown\")\n\n", "    # Scale new numeric columns\n", "    for col in NEW_NUM_COLS:\n", "        mn = df[col].min(skipna=True)\n", "        mx = df[col].max(skipna=True)\n", "        rng = mx - mn\n", "        if pd.isna(mn) or pd.isna(mx) or rng == 0:\n", "            df[col + \"_scaled\"] = 0.0\n", "        else:\n", "            df[col + \"_scaled\"] = (df[col] - mn) / rng\n", "    out_path = OUT_DIR / path.name\n", "    df.to_csv(out_path, index=False)\n", "    print(f\"Wrote {out_path}\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"All done.\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}