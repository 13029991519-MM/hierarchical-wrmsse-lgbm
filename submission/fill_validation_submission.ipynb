{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b222cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fill the _validation part of submission using models trained on d_1–1913.\n",
    "Keeps existing _evaluation predictions (e.g., from future_finaldata/submission.csv).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e04f266",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0fe387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import gc\n",
    "import json\n",
    "import pathlib\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e736f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d87033",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import train_lgbm_baseline as lgb_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d923ce15",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TYPES = (\"main\", \"c_model\")\n",
    "SUMMARY_PATH = pathlib.Path(\"weight_v2/summary_delay120_v2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9c258a",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_START = 1914\n",
    "VAL_END = 1941  # inclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374147f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_single_model(train_df: pd.DataFrame, val_df: pd.DataFrame, feature_cols: List[str], params: dict):\n",
    "    model, _ = lgb_base.train_lgbm(train_df, val_df, feature_cols, params)\n",
    "    preds = model.predict(val_df[feature_cols], num_iteration=model.best_iteration_)\n",
    "    out = val_df[[\"id\", \"d\"]].copy()\n",
    "    out[\"pred\"] = preds\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e57cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_summary() -> dict[str, dict]:\n",
    "    if not SUMMARY_PATH.exists():\n",
    "        return {}\n",
    "    with SUMMARY_PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        entries = json.load(f)\n",
    "    return {\n",
    "        entry[\"stores\"][0]: entry\n",
    "        for entry in entries\n",
    "        if isinstance(entry, dict) and isinstance(entry.get(\"stores\"), list) and entry[\"stores\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6175396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_params(store: str, summary: dict[str, dict], model_type: str) -> dict:\n",
    "    entry = summary.get(store, {})\n",
    "    key = \"main_params\" if model_type == \"main\" else \"c_params\"\n",
    "    params = entry.get(key)\n",
    "    if isinstance(params, dict):\n",
    "        return params\n",
    "    return lgb_base.merge_store_params(store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8775d60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--stores\",\n",
    "        type=str,\n",
    "        default=\"\",\n",
    "        help=\"comma-separated store ids to process (default: all)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--model-type\",\n",
    "        type=str,\n",
    "        choices=MODEL_TYPES,\n",
    "        default=\"main\",\n",
    "        help=\"Which model type to train for validation fill (default: main).\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--out\",\n",
    "        type=pathlib.Path,\n",
    "        help=\"Optional output path for the filled submission\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    base_submission_path = pathlib.Path(\"future_finaldata/submission.csv\")\n",
    "    sample_path = pathlib.Path(\"data/sample_submission.csv\")\n",
    "    model_type = args.model_type\n",
    "    default_out = (\n",
    "        pathlib.Path(\"future_finaldata/submission_with_val.csv\")\n",
    "        if model_type == \"main\"\n",
    "        else pathlib.Path(\"future_finaldata/submission_with_val_cmodel.csv\")\n",
    "    )\n",
    "    out_path = args.out or default_out\n",
    "    summary = load_summary()\n",
    "\n",
    "    if not base_submission_path.exists():\n",
    "        raise FileNotFoundError(f\"Base submission not found: {base_submission_path}\")\n",
    "\n",
    "    sub = pd.read_csv(base_submission_path)\n",
    "    sample = pd.read_csv(sample_path)\n",
    "\n",
    "    # Ensure F columns are float to avoid dtype warnings\n",
    "    f_cols = [c for c in sub.columns if c.startswith(\"F\")]\n",
    "    sub[f_cols] = sub[f_cols].astype(float)\n",
    "\n",
    "    if args.stores:\n",
    "        stores = [s.strip() for s in args.stores.split(\",\") if s.strip()]\n",
    "    else:\n",
    "        stores = list(lgb_base.STORE_LIST)\n",
    "    for store in stores:\n",
    "        print(f\"Processing store {store} for validation fill...\")\n",
    "        train_df, val_df, feature_cols_core, feature_cols_full = lgb_base.build_datasets([store])\n",
    "        # ensure numeric day for slicing; keep original d for pivot\n",
    "        train_df[\"d_num\"] = pd.to_numeric(train_df[\"d\"].astype(str).str.replace(\"d_\", \"\"), errors=\"coerce\")\n",
    "        val_df[\"d_num\"] = pd.to_numeric(val_df[\"d\"].astype(str).str.replace(\"d_\", \"\"), errors=\"coerce\")\n",
    "\n",
    "        # keep only validation slice d_1914–1941\n",
    "        val_df = val_df[(val_df[\"d_num\"] >= VAL_START) & (val_df[\"d_num\"] <= VAL_END)]\n",
    "        feature_cols = feature_cols_core if model_type == \"main\" else feature_cols_full\n",
    "        params = select_params(store, summary, model_type)\n",
    "        preds_df = train_single_model(train_df, val_df, feature_cols, params)\n",
    "\n",
    "        # pivot to wide F1..F28\n",
    "        wide = preds_df.pivot(index=\"id\", columns=\"d\", values=\"pred\")\n",
    "        wide = wide.reindex(columns=[f\"d_{d}\" for d in range(VAL_START, VAL_END + 1)])\n",
    "        # map d_1914 -> F1, ...\n",
    "        f_map = {f\"d_{d}\": f\"F{d - VAL_START + 1}\" for d in range(VAL_START, VAL_END + 1)}\n",
    "\n",
    "        sub_ids = set(sub[\"id\"])\n",
    "        for rid, row in wide.iterrows():\n",
    "            if rid.endswith(\"_evaluation\"):\n",
    "                sub_id = rid.replace(\"_evaluation\", \"_validation\")\n",
    "            elif rid.endswith(\"_validation\"):\n",
    "                sub_id = rid\n",
    "            else:\n",
    "                sub_id = f\"{rid}_validation\"\n",
    "            if sub_id not in sub_ids:\n",
    "                continue\n",
    "            for d_col, f_col in f_map.items():\n",
    "                sub.loc[sub[\"id\"] == sub_id, f_col] = row[d_col]\n",
    "        # free memory\n",
    "        del train_df, val_df, preds_df, wide\n",
    "        gc.collect()\n",
    "\n",
    "    # sanity: keep rows/cols aligned to sample\n",
    "    sub = sub.loc[:, sample.columns]\n",
    "    sub.to_csv(out_path, index=False)\n",
    "    print(f\"Wrote submission with validation filled: {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758202ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
